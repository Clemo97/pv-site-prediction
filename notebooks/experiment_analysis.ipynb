{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf36ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of the output of experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a073067",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9d9d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import pvlib\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "\n",
    "def _(df, *args, **kwargs):\n",
    "    print(len(df))\n",
    "    display(df.head(*args, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c7bd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's always annoying to set the working directory: we use an environment variable defined in the Makefile.\n",
    "CWD = os.environ.get(\"CWD\")\n",
    "if CWD:\n",
    "    os.chdir(CWD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da513a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3dc34d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inferred_meta = pd.read_csv(\"data/meta_inferred.csv\").set_index(\"ss_id\")\n",
    "_(inferred_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45e7020",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\"data/metadata_sensitive.csv\").set_index(\"ss_id\")\n",
    "_(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5399c26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_to(x, to):\n",
    "    return round(x / to) * to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e92615",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ROUND_HORIZON_TO = 4\n",
    "ROUND_PRED_TO = 30\n",
    "WIDTH = 120\n",
    "\n",
    "\n",
    "def load_models(names):\n",
    "    dfs = []\n",
    "    for name in names:\n",
    "        try:\n",
    "            df = pd.read_csv(f\"exp_results/{name}/errors.csv\")\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "        df[\"model\"] = name\n",
    "        dfs.append(df)\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    return df\n",
    "\n",
    "\n",
    "def error_chart(names):\n",
    "\n",
    "    df = load_models(names)\n",
    "\n",
    "    df[\"ts\"] = pd.to_datetime(df[\"ts\"])\n",
    "    df = df[df[\"metric\"] == \"mae\"]\n",
    "\n",
    "    df[\"pred_ts\"] = df[\"ts\"] + pd.to_timedelta(df[\"horizon\"], unit=\"minute\")\n",
    "\n",
    "    bad_pvs = df[(df[\"pred_ts\"].dt.hour < 1) & ~df[\"y\"].isnull()]\n",
    "    remove_pvs = bad_pvs[\"pv_id\"].unique()\n",
    "    print(f\"REMOVING PVS WITH NIGHT DATA: {remove_pvs}\")\n",
    "    df = df[~df[\"pv_id\"].isin(remove_pvs)]\n",
    "\n",
    "    df = df.join(inferred_meta[[\"factor\", \"capacity\"]], on=\"pv_id\")\n",
    "    # df = df.join(meta[['latitude', 'longitude']], on=\"pv_id\")\n",
    "\n",
    "    # Normalizing\n",
    "    # Using my own \"capacity\"\n",
    "    # df[\"weighted_error\"] = df[\"error\"] / df[\"factor\"]\n",
    "\n",
    "    # Using quantile(0.99) as capacity.\n",
    "    # Need some unit adjustement. See infer_pv_metadata.py\n",
    "    df[\"weighted_error\"] = df[\"error\"] / (df[\"capacity\"] * 1000 / 12)\n",
    "\n",
    "    df[\"horizon\"] = df[\"horizon\"] / 60.0\n",
    "    df = df[~df[\"error\"].isnull()]\n",
    "\n",
    "    # Round the prediction hour and the horizon for more concise charts.\n",
    "    df[\"pred_hour\"] = df[\"pred_ts\"].dt.hour * 60 + round_to(\n",
    "        df[\"pred_ts\"].dt.minute, ROUND_PRED_TO\n",
    "    )\n",
    "    df[\"horizon\"] = round_to(df[\"horizon\"], ROUND_HORIZON_TO)\n",
    "\n",
    "    df = (\n",
    "        df[[\"model\", \"horizon\", \"weighted_error\", \"pred_hour\"]]\n",
    "        .groupby([\"model\", \"pred_hour\", \"horizon\"])\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    df[\"pred_hour\"] = pd.to_timedelta(df[\"pred_hour\"], unit=\"minute\")\n",
    "    df[\"date\"] = pd.Timestamp(2023, 1, 1)\n",
    "    df[\"pred_hour\"] = df[\"date\"] + df[\"pred_hour\"]\n",
    "\n",
    "    print(f\"Mean Error: {df.groupby(['model'])['weighted_error'].mean()}\")\n",
    "\n",
    "    chart = (\n",
    "        alt.Chart(df)\n",
    "        .mark_line()\n",
    "        .encode(\n",
    "            x=alt.X(\"hoursminutes(pred_hour)\", title=\"Time *at prediction*\"),\n",
    "            y=alt.Y(\"weighted_error\", title=\"Error\"),\n",
    "            color=alt.Color(\"model\", sort=names),\n",
    "            column=alt.Column(\"horizon:O\", spacing=1),\n",
    "        )\n",
    "        .properties(\n",
    "            height=WIDTH * 1.5,\n",
    "            width=WIDTH,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    chart2 = (\n",
    "        alt.Chart(df)\n",
    "        .mark_bar()\n",
    "        .encode(\n",
    "            x=alt.X(\"model\"),\n",
    "            y=alt.Y(\"mean(weighted_error)\", title=\"Error\"),\n",
    "            color=alt.Color(\"model\", sort=names),\n",
    "            column=alt.Column(\"horizon:O\"),\n",
    "        )\n",
    "        .properties(\n",
    "            height=125,\n",
    "            width=30,\n",
    "        )\n",
    "    )\n",
    "    return chart, chart2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d042cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "names = [\n",
    "    p.stem for p in pathlib.Path(\"exp_results\").iterdir() if not p.stem.startswith(\".\")\n",
    "]\n",
    "# names = [\"baseline-no-nwp\", 'new-history-no-nwp-3', 'new-history-no-nwp-4']\n",
    "names = [\n",
    "    \"cache\",\n",
    "    \"cache-new-history\",\n",
    "    \"new-history-no-nwp\",\n",
    "    \"cache-new-history-2nd\",\n",
    "    \"cache-new-history-no-last\",\n",
    "    \"cache-new-history-1h\",\n",
    "    \"cache-new-history-20min\",\n",
    "]\n",
    "\n",
    "\n",
    "c1, c2 = error_chart(names)\n",
    "display(c1)\n",
    "display(c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c946c02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_models(names)\n",
    "# df[\"ts\"] = pd.to_datetime(df[\"ts\"])\n",
    "# df = df[df[\"metric\"] == \"mae\"]\n",
    "# df = df.join(inferred_meta[[\"factor\"]], on=\"pv_id\")\n",
    "# df = df.rename(columns={\"factor\": \"capacity\"})\n",
    "# df[\"pred_ts\"] = df[\"ts\"] + df[\"horizon\"].map(lambda x: pd.Timedelta(minutes=x))\n",
    "# df[\"weighted_error\"] = df[\"capacity\"] * df[\"error\"]\n",
    "# df[\"ts_hour\"] = df[\"ts\"].dt.hour.astype(str) + \":\" + df[\"ts\"].dt.minute.astype(str)\n",
    "# df[\"horizon\"] = df[\"horizon\"] / 60.0\n",
    "# df = df[~df[\"error\"].isnull()]\n",
    "_(df)\n",
    "\n",
    "scale = alt.Scale()  # clamp=True, domain=(0.01, 100))\n",
    "\n",
    "chart = (\n",
    "    alt.Chart(df.sample(1000))\n",
    "    .mark_circle(opacity=0.5)\n",
    "    .encode(x=alt.X(\"y\", scale=scale), y=alt.Y(\"pred\", scale=scale), color=\"model\")\n",
    "    .properties(width=400, height=400)\n",
    ") + (\n",
    "    alt.Chart(pd.DataFrame(dict(x=[0, 300], y=[0, 300])))\n",
    "    .mark_line(color=\"black\")\n",
    "    .encode(x=\"x\", y=\"y\")\n",
    ")\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8811bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
