{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10ce297",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e832aac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "from psp.data import C, trim_pv, filter_rows, get_max_power_for_time_of_day\n",
    "\n",
    "\n",
    "def _(df, *args, **kwargs):\n",
    "    print(len(df))\n",
    "    display(df.head(*args, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767ab8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's always annoying to set the working directory: we use an environment variable defined in the Makefile.\n",
    "CWD = os.environ.get(\"CWD\")\n",
    "if CWD:\n",
    "    os.chdir(CWD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcec368",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b359760",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_parquet(\"data/5min.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76b092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load already prepared sampled datasets.\n",
    "# See `psp/scripts/simplify_data.py`.\n",
    "dir_ = pathlib.Path(\"./data/5min\")\n",
    "for f in dir_.iterdir():\n",
    "    if \"all\" not in f.stem:\n",
    "        continue\n",
    "    #     print(f.stem)\n",
    "    df = pd.read_parquet(f)\n",
    "    name = \"df5_\" + f.stem.replace(\"5min_\", \"\")\n",
    "    locals()[name] = df\n",
    "    #     print(f.stem)\n",
    "    print(f\"{name}: {len(df)}\")\n",
    "# df5_100.head()\n",
    "# df5_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebd9f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta = pd.read_csv(\"./data/metada_sensitive.csv\")\n",
    "meta = pd.read_csv(\"data/metada_sensitive.csv\")\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e4f1fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alt.Chart(meta).mark_bar().encode(\n",
    "    x=alt.X(\"tilt\", bin=alt.Bin(maxbins=100)), y=\"count()\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d6310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of `ss_id`\n",
    "len(df5[\"ss_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef94e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of data points\n",
    "print(len(df5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a1dee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = df5_10k.copy()\n",
    "# data = data.rename(columns={'generation_wh': 'power'})\n",
    "max_ = 100\n",
    "num_bins = 10\n",
    "steps = max_ / num_bins\n",
    "print(steps)\n",
    "display(data.head())\n",
    "(\n",
    "    alt.Chart(data)\n",
    "    .mark_bar()\n",
    "    .encode(x=alt.X(C.POWER, bin=alt.Bin(extent=[0, max_], step=steps)), y=\"count()\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb91c3f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = df5_100_1M.copy()\n",
    "num_bins = 20\n",
    "max_ = 1000\n",
    "(\n",
    "    alt.Chart(data)\n",
    "    .mark_bar()\n",
    "    .encode(\n",
    "        x=alt.X(\n",
    "            C.POWER, bin=alt.Bin(extent=[0, max_], step=max_ // num_bins), title=\"\"\n",
    "        ),\n",
    "        y=alt.Y(\"count()\", title=\"\"),\n",
    "        facet=alt.Facet(C.ID, columns=16),\n",
    "    )\n",
    "    .resolve_scale(\n",
    "        x=\"independent\",\n",
    "        y=\"independent\",\n",
    "    )\n",
    "    .properties(width=50, height=50)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77984cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find some stats for each system.\n",
    "# In particular, find the max power.\n",
    "data = df5_1M[[C.ID, C.POWER]].groupby(C.ID).agg([\"mean\", \"std\", \"max\", \"min\", \"count\"])\n",
    "data.columns = data.columns.get_level_values(1)\n",
    "\n",
    "ss_stats = data\n",
    "ss_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b2f3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ss_stats.reset_index()\n",
    "(\n",
    "    alt.Chart(data)\n",
    "    .mark_bar()\n",
    "    .encode(y=\"count()\", x=alt.X(\"count\", bin=alt.Bin(maxbins=100)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9bd308",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = ss_stats.reset_index()\n",
    "(\n",
    "    alt.Chart(data)\n",
    "    .mark_bar()\n",
    "    .encode(y=\"count()\", x=alt.X(\"mean\", bin=alt.Bin(maxbins=100)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63bec67",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = ss_stats.reset_index()\n",
    "\n",
    "(\n",
    "    alt.Chart(data)\n",
    "    .mark_bar()\n",
    "    .encode(y=\"count()\", x=alt.X(\"max\", bin=alt.Bin(maxbins=100)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b0d217",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ss_stats\n",
    "# data['max/mean'] = data['max'] / data['mean']\n",
    "max_mean = 150\n",
    "chart = (\n",
    "    alt.Chart(data)\n",
    "    .mark_point()\n",
    "    .encode(x=alt.X(\"mean\", scale=alt.Scale(domain=[0, max_mean], clamp=True)), y=\"max\")\n",
    ")\n",
    "# reg = chart.transform_regression('mean', 'max').mark_line()\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "model.fit(data[[\"mean\"]], y=data[\"max\"])\n",
    "\n",
    "line_data = pd.DataFrame(dict(x=[0, max_mean]))\n",
    "line_data[\"y\"] = model.predict(line_data[[\"x\"]])\n",
    "line_data\n",
    "\n",
    "line = alt.Chart(line_data).mark_line(color=\"red\").encode(x=\"x\", y=\"y\")\n",
    "\n",
    "display(chart + line)\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b8f332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's use that linear model to compute a capacity for each ss_id.\n",
    "# data = df5_10k\n",
    "# data = data[[C.ID, 'power']].groupby(C.ID).mean()\n",
    "# data['capacity'] = model.coef_[0] * data['power']\n",
    "# data = data.drop(columns='power')\n",
    "\n",
    "# capacities = data\n",
    "# capacities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b0f2fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = df5_100\n",
    "group_days = 14\n",
    "data = (\n",
    "    data[[C.ID, C.DATE, C.POWER]]\n",
    "    .groupby([C.ID, pd.Grouper(freq=f\"{group_days}D\", key=C.DATE)])\n",
    "    # Sum the power\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "data[\"energy\"] = data[C.POWER] * 5 / 60 / group_days\n",
    "display(data.head())\n",
    "\n",
    "data[C.DATE] = pd.to_datetime(data[C.DATE])\n",
    "\n",
    "main = (\n",
    "    alt.Chart(data)\n",
    "    .mark_line()\n",
    "    .encode(\n",
    "        x=alt.X(C.DATE, title=\"\"),\n",
    "        y=alt.Y(\"energy\", title=\"\"),\n",
    "        facet=alt.Facet(\n",
    "            C.ID, title=\"\", header=alt.Header(title=None, labelFontSize=0), columns=12\n",
    "        ),\n",
    "    )\n",
    "    .properties(height=30, width=100)\n",
    ")\n",
    "\n",
    "main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1c75de",
   "metadata": {},
   "outputs": [],
   "source": [
    "LON_RANGE = [-4.537402, -3.940503]\n",
    "LAT_RANGE = [55.722169, 56.000524]\n",
    "\n",
    "m = meta.copy()\n",
    "for col, (low, high) in zip([C.LAT, C.LON], [LAT_RANGE, LON_RANGE]):\n",
    "    m = filter_rows(m, (m[col] < high) & (m[col] > low), \"filter on \" + col)\n",
    "ss_box = m[C.ID].unique().tolist()\n",
    "print(len(ss_box))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167ff00b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = df5_glasgow  # .copy()\n",
    "\n",
    "# Filter by system\n",
    "# data = filter_rows(data, data[C.ID].isin(ss_box), 'system id')\n",
    "\n",
    "\n",
    "# Keep one year\n",
    "data = filter_rows(data, data[C.DATE].dt.year == 2019, \"2019\")\n",
    "\n",
    "data = filter_rows(data, data[C.POWER] > 0.2, \"> 0.2\")\n",
    "data = filter_rows(data, data[C.DATE].dt.hour > 4, \"after 4am\")\n",
    "data = filter_rows(data, data[C.DATE].dt.hour < 21, \"before 9pm\")\n",
    "\n",
    "# Filter days\n",
    "data[\"day\"] = data[C.DATE].dt.dayofyear\n",
    "keep_days = 14\n",
    "offset = (365 - keep_days) // 2\n",
    "before = offset\n",
    "after = 365 - offset\n",
    "# data = data[]\n",
    "data = filter_rows(\n",
    "    data, (data[\"day\"] > offset) & (data[\"day\"] <= 365 - offset), \"N days\"\n",
    ")\n",
    "\n",
    "\n",
    "# Keep one point every ...\n",
    "# data = (\n",
    "#     data.groupby([C.ID, pd.Grouper(freq=\"30min\", key=C.DATE)])\n",
    "#     # Sum the power\n",
    "#     .mean().reset_index()\n",
    "# )\n",
    "\n",
    "data.head()\n",
    "\n",
    "# data = data[[C.ID, C.EFF, 'day', 'time']]\n",
    "# data =data[ data['day'] < 5]\n",
    "# data = data[data[C.ID] < 6000]\n",
    "# data = data[data['day'] % 4 == 0]\n",
    "display(data.head())\n",
    "\n",
    "# Hack to sort by latitude.\n",
    "data[\"lat_id\"] = data[[C.LAT, C.ID]].apply(\n",
    "    lambda row: f\"{row[C.LAT]:.2f}00{int(row[C.ID])}\", axis=1\n",
    ")\n",
    "# ... or longitude\n",
    "# note that I'm concatenating the numbers - it's a hack because there are negative values and they won't\n",
    "# be sorted properly as strings\n",
    "data[\"lon_id\"] = data[[C.LON, C.ID]].apply(\n",
    "    lambda row: f\"{row[C.LON]:.2f}00{int(row[C.ID])}\", axis=1\n",
    ")\n",
    "data[\"lon_id\"] = data[\"lon_id\"].astype(float)\n",
    "\n",
    "\n",
    "display(data.head())\n",
    "# print(len(data[C.ID].unique()))\n",
    "# display(meta[meta[C.ID].isin(data[C.ID].unique())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905eeb4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from psp.data import join_efficiency\n",
    "# data2 = join_efficiency(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6f5411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b508c80f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "main = (\n",
    "    alt.Chart(data)\n",
    "    .mark_line()\n",
    "    .encode(\n",
    "        x=alt.X(f\"hoursminutes({C.DATE})\", title=\"\", axis=None),\n",
    "        y=alt.Y(C.EFF, title=\"\", axis=None),\n",
    "        row=alt.Row(\n",
    "            #             'day',\n",
    "            #             \"lon_id\",\n",
    "            \"lat_id\",\n",
    "            header=alt.Header(title=None, labelFontSize=0),\n",
    "            title=\"PV System\",\n",
    "            spacing=-10,\n",
    "            #             spacing=100,\n",
    "            sort=\"descending\",\n",
    "        ),\n",
    "        column=alt.Column(\n",
    "            f\"day\",\n",
    "            #             'lon_id',\n",
    "            header=alt.Header(title=None, labelFontSize=0),\n",
    "            spacing=-10,\n",
    "            #             title='Day'\n",
    "        ),\n",
    "    )\n",
    "    .properties(height=30, width=100)\n",
    "    .configure_view(strokeWidth=0)\n",
    ")\n",
    "main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17740638",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Geographical distribution of the PV systems.\n",
    "data = meta.copy()  # .sample(100)\n",
    "data[\"log(kwp)\"] = np.log(data[\"kwp\"])\n",
    "data[\"one\"] = 1.0\n",
    "px.scatter_geo(\n",
    "    data,\n",
    "    lon=C.LON,\n",
    "    lat=C.LAT,\n",
    "    fitbounds=\"locations\",\n",
    "    size=\"one\",\n",
    "    size_max=3,\n",
    "    color=\"log(kwp)\",\n",
    "    #     width=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b2ff71",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = df5_1M\n",
    "# data = df5_10k\n",
    "# display(data.head())\n",
    "\n",
    "# data = data.set_index([])\n",
    "\n",
    "data = (\n",
    "    data[[C.EFF, C.DATE]]\n",
    "    .groupby(\n",
    "        [\n",
    "            pd.Grouper(key=C.DATE, freq=\"1M\"),\n",
    "            data[C.DATE].dt.time,\n",
    "            #     pd.Grouper(key=C.DATE, freq='1H')\n",
    "        ]\n",
    "    )\n",
    "    .max()\n",
    ")\n",
    "# data[C.DATE].dt.time]).max()\n",
    "# display(data.head())\n",
    "data.index = data.index.set_names(\n",
    "    (\"month\", \"time\")\n",
    ")  # rename(index={(C.DATE, C.DATE): ('month', 'time')})\n",
    "# data['minute'] = pd.to_datetime(data['time'])\n",
    "display(data.head())\n",
    "\n",
    "# print(data.index)\n",
    "data = data.groupby(level=\"month\").rolling(12).mean()\n",
    "data.index = data.index.droplevel(0)\n",
    "\n",
    "display(data.head())\n",
    "\n",
    "data = data.reset_index()\n",
    "\n",
    "# data['time'] = data['time'].astype(str)\n",
    "# display(data.head())\n",
    "data[\"time\"] = pd.to_datetime(data[\"time\"], format=\"%H:%M:%S\")\n",
    "# display(data.tail())\n",
    "# display(data.dtypes)\n",
    "\n",
    "(\n",
    "    alt.Chart(data)\n",
    "    .mark_line()\n",
    "    .encode(\n",
    "        # x=f'hourminute({C.DATE})',\n",
    "        x=alt.X(\"hoursminutes(time)\", title=\"\"),\n",
    "        y=alt.Y(\"max(efficiency)\", title=\"\"),\n",
    "        color=alt.Color(\n",
    "            \"month(month):N\", title=\"Month\", scale=alt.Scale(scheme=\"viridis\")\n",
    "        ),  # , scale=alt.Scale(scheme={'name': 'rainbow', 'extent': [-100, 100]})),\n",
    "        #         column=alt.Column('month(month)', title=''),\n",
    "        facet=alt.Facet(\"year(month)\", title=\"\", columns=2),\n",
    "    )\n",
    "    .properties(\n",
    "        width=400,\n",
    "        height=200,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9d2b34",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# data = df5_1M\n",
    "# data = df5_100_1M\n",
    "data = df5_glasgow  # _10k\n",
    "# keep 10\n",
    "# ss_ids = data[C.ID].unique()[:10]\n",
    "# data = filter_rows(data, data[C.ID].isin(ss_ids), 'keep 10')\n",
    "# display(data.head())\n",
    "\n",
    "# data = data.set_index([])\n",
    "\n",
    "data = (\n",
    "    data[[C.ID, C.EFF, C.DATE]]\n",
    "    .groupby(\n",
    "        [\n",
    "            C.ID,\n",
    "            pd.Grouper(key=C.DATE, freq=\"1M\"),\n",
    "            #     pd.Grouper(key=C.DATE, freq='1H'),\n",
    "            data[C.DATE].dt.hour,\n",
    "            #     pd.Grouper(key=C.DATE, freq='1H')\n",
    "        ]\n",
    "    )\n",
    "    .max()\n",
    ")\n",
    "\n",
    "# data[C.DATE].dt.time]).max()\n",
    "display(data.head())\n",
    "data.index = data.index.set_names(\n",
    "    (C.ID, \"month\", \"hour\")\n",
    ")  # rename(index={(C.DATE, C.DATE): ('month', 'time')})\n",
    "# data['minute'] = pd.to_datetime(data['time'])\n",
    "display(data.head())\n",
    "\n",
    "# print(data.index)\n",
    "# data = data.groupby(level=[C.ID, 'month']).rolling(12).mean()\n",
    "# data.index = data.index.droplevel(0)\n",
    "# data.index = data.index.droplevel(0)\n",
    "\n",
    "display(data.head())\n",
    "\n",
    "data = data.reset_index()\n",
    "\n",
    "# data['time'] = data['time'].astype(str)\n",
    "display(data.head())\n",
    "# data['time'] = pd.to_datetime(data['time'], format='%H:%M:%S')\n",
    "# display(data.tail())\n",
    "# display(data.dtypes)\n",
    "\n",
    "(\n",
    "    alt.Chart(data)\n",
    "    .mark_line(opacity=0.2)\n",
    "    .encode(\n",
    "        # x=f'hourminute({C.DATE})',\n",
    "        x=alt.X(\"hour\", title=\"\"),\n",
    "        y=alt.Y(\"efficiency\", title=\"\"),\n",
    "        row=alt.Row(\"year(month)\", title=\"\"),\n",
    "        column=alt.Column(\"month(month)\"),\n",
    "        color=alt.Color(C.ID + \":N\", scale=alt.Scale(range=[\"gray\"]))\n",
    "        # color=alt.Color('month(month):N', title='Month', scale=alt.Scale(scheme='viridis')),#, scale=alt.Scale(scheme={'name': 'rainbow', 'extent': [-100, 100]})),\n",
    "        #         column=alt.Column('month(month)', title=''),\n",
    "        #         column=alt.Column('year(month)', title=''),\n",
    "        #         row=C.ID,\n",
    "    )\n",
    "    .properties(\n",
    "        width=100,\n",
    "        height=100,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26260529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep 10 systems\n",
    "# all the sytems\n",
    "all_ids = df5_glasgow[C.id].unique().tolist()\n",
    "meta.head()\n",
    "meta_glas = meta[meta[C.id].isin(all_ids)]\n",
    "len(meta_glas)\n",
    "keep_ids = meta_glas.sort_values(\"latitude_rounded\").iloc[:10][C.id].tolist()\n",
    "\n",
    "data = df5_glasgow[df5_glasgow[C.id].isin(keep_ids)].copy()  # .sample(10000).copy()\n",
    "# sample * the timestamps *\n",
    "timestamps = np.random.choice(data[C.date].unique(), 1000)\n",
    "\n",
    "data = data[data[C.date].isin(timestamps)]\n",
    "\n",
    "data[C.id] = data[C.id].astype(str)\n",
    "\n",
    "display(data.head())\n",
    "len(data)\n",
    "\n",
    "display(data.head())\n",
    "ids = data[C.id].unique().tolist()\n",
    "data = data.pivot(index=C.date, columns=C.id, values=C.eff).reset_index()\n",
    "display(data.tail())\n",
    "\n",
    "alt.Chart(data).mark_circle(opacity=0.6, size=5).encode(\n",
    "    alt.X(alt.repeat(\"column\"), type=\"quantitative\", title=\"\"),\n",
    "    alt.Y(alt.repeat(\"row\"), type=\"quantitative\", title=\"\"),\n",
    "    color=alt.Color(f\"month({C.date}):N\", scale=alt.Scale(scheme=\"viridis\")),\n",
    ").properties(width=100, height=100).repeat(row=ids, column=ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcd1e4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(df5_glasgow.dtypes)\n",
    "# Let's compare correlations and distances.\n",
    "timestamps = df5_glasgow[C.date].unique()[:1000].tolist()\n",
    "data = df5_glasgow.copy()\n",
    "data = data[data[C.date].isin(timestamps)]\n",
    "\n",
    "\n",
    "ids = data[C.id].unique().tolist()\n",
    "print(ids)\n",
    "data = data.pivot(index=C.date, columns=C.id, values=C.power)\n",
    "\n",
    "\n",
    "corrs = data.corr()\n",
    "\n",
    "# print(ids)\n",
    "display(corrs.head())\n",
    "from psp.gis import approx_distance\n",
    "\n",
    "\n",
    "# distances.loc[123, 123] = 0.\n",
    "# distances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d00669e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df843038",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cef553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save!\n",
    "distance.to_csv(\"data/pv_distances.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7442bc5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c = corrs.stack()\n",
    "d = distances.stack()\n",
    "display(c.head())\n",
    "display(d.head())\n",
    "\n",
    "# remove distance of 0\n",
    "\n",
    "data = pd.concat([c, d], axis=1).rename(columns={0: \"correlation\", 1: \"distance\"})\n",
    "data = data[data[\"distance\"] > 0]\n",
    "# data.head()\n",
    "data.tail()\n",
    "\n",
    "alt.Chart(data.reset_index(drop=True)).mark_circle().encode(\n",
    "    x=alt.X(\"distance\"),\n",
    "    y=\"correlation\",\n",
    ").properties(width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49f05a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate distances between PV sites.\n",
    "# This is slow to compute so we save the file for later reloading!\n",
    "import tqdm\n",
    "from psp.gis import approx_distance\n",
    "\n",
    "# Get the ss_id for which we have data.\n",
    "ids = df5_1M[C.id].unique().tolist()\n",
    "print(f\"Distances for {len(ids)} systems\")\n",
    "\n",
    "rows = []\n",
    "for i in tqdm.tqdm(range(len(m))):\n",
    "    s1 = m.iloc[i]\n",
    "    #     print(s1)\n",
    "    id1, lat1, lon1 = s1[[C.id, C.lat, C.lon]]\n",
    "    for j in range(i + 1, len(m)):\n",
    "        s2 = m.iloc[j]\n",
    "        id2, lat2, lon2 = s2[[C.id, C.lat, C.lon]]\n",
    "        d = approx_distance((lat1, lon1), (lat2, lon2)) / 1000\n",
    "        rows.append((int(id1), int(id2), d))\n",
    "#         break\n",
    "#     break\n",
    "#         all_distances.loc[id1, id2] = d\n",
    "#         all_distances.loc[id2, id1] = d\n",
    "# print(rows)\n",
    "distances = pd.DataFrame.from_records(rows, columns=[\"ss_id1\", \"ss_id2\", \"distance\"])\n",
    "distances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fbc5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save!\n",
    "# NOTE I saved distances as integer by mistake, needs to rerun and resave and delete this comment.\n",
    "distances.to_csv(\"data/pv_distances.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cd323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load distances\n",
    "distances = pd.read_csv(\"data/pv_distances.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8714977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe3cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"go\")\n",
    "d = distances.sort_values(\"distance\")[:50]  # .set_index(['ss_id1', 'ss_id2'])\n",
    "couples = d.copy()\n",
    "print(d[\"distance\"].max())\n",
    "\n",
    "couples = couples.join(meta.set_index(C.id)[\"kwp\"], on=\"ss_id1\").rename(\n",
    "    columns={\"kwp\": \"kwp1\"}\n",
    ")\n",
    "couples = couples.join(meta.set_index(C.id)[\"kwp\"], on=\"ss_id2\", rsuffix=\"2\")\n",
    "_(couples)\n",
    "# d = distances[distances['distance'] < 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b4fb12",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(len(d))\n",
    "# display(d.tail())\n",
    "\n",
    "# All the systems with small enough distances\n",
    "ids = set(d[\"ss_id1\"].tolist()) | set(d[\"ss_id2\"].tolist())\n",
    "\n",
    "# A sample of 1k timestamps\n",
    "timestamps = df5_1M[C.date].unique()  # [:10000]#\n",
    "print(len(timestamps))\n",
    "\n",
    "df = df5_all\n",
    "neighbor_data = df[df[C.date].isin(timestamps) & df[C.id].isin(ids)].copy()\n",
    "# neighbor_data = df5_all[df5_all[C.date].isin(timestamps) & df5_all[C.id].isin(ids)].copy()\n",
    "print(len(neighbor_data))\n",
    "# c = corrs.stack().to_frame().reset_index(names=['ss_id1', 'ss_id2']).rename(columns={0: 'correlation'}).set_index(['ss_id1', 'ss_id2'])\n",
    "# display(c.tail())\n",
    "\n",
    "# d.join(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d74c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3e8911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neighbor_data[C.date] = neighbor_data[C.date].b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72aad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "power = neighbor_data.sort_values([C.id, C.date]).set_index([C.id, C.date])[[C.power]]\n",
    "power.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae4fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "power.index.get_level_values(0).unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e0f234",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = power.index.get_level_values(0).unique().tolist()[:2]\n",
    "\n",
    "power.loc[idx].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1777e4e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "capacity = get_max_power_for_time_of_day(power, radius=7, min_records=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea704c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420e5193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# capacity.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61e3ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cap.sort_index()\n",
    "# min_cap = min_cap.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac25755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_(capacity)\n",
    "# print(len(capacity.index.get_level_values(0).unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088cf6d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rolling window on the capacity to smooth it out. It should be smooth it's a theoretical model!\n",
    "sm = (\n",
    "    capacity.reset_index()\n",
    "    .groupby([C.id])\n",
    "    .rolling(\"1h\", on=C.date, center=True, min_periods=4, closed=\"both\")\n",
    "    .mean()\n",
    "    .set_index([C.date], append=True)\n",
    "    .reset_index(level=1, drop=True)\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "\n",
    "_(sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efe0456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1d5c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909659fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# p = power.loc[ids].sort_index()\n",
    "smooth_cap = smooth_cap.loc[ids].sort_index()\n",
    "smooth_min_cap = smooth_min_cap.loc[ids].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2ac562",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# power per cap\n",
    "# ppc = p / c\n",
    "power = power.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14077b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sm.copy().reset_index()\n",
    "data = data[data[C.id] == 6667]\n",
    "data = data[data[C.date].dt.year == 2020]\n",
    "data = data[data[C.date].dt.month == 5]\n",
    "# data = data[data[C.date].dt.day < 7]\n",
    "\n",
    "alt.Chart(data).mark_line().encode(\n",
    "    x=f\"hoursminutes({C.date})\",\n",
    "    y=C.power,\n",
    "    facet=alt.Facet(f\"yearmonthdate({C.date})\", columns=6),\n",
    ").properties(width=100, height=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ae5ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ppc.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6134f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e254de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merge the datasets\n",
    "mer = power.copy()\n",
    "mer[\"max\"] = capacity\n",
    "mer[\"smooth_max\"] = sm\n",
    "_(mer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cd3d1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find the time at which we get our max capacity, for each ss_id for each day\n",
    "\n",
    "x = sm.copy()\n",
    "x = x.reset_index(1)\n",
    "x[\"date\"] = x[C.date].dt.date\n",
    "# _(x)\n",
    "# x['date'] =\n",
    "\n",
    "x = (\n",
    "    x.reset_index()\n",
    "    .sort_values([C.id, \"date\", C.power], ascending=False)\n",
    "    .drop_duplicates([C.id, \"date\"])\n",
    ")\n",
    "\n",
    "date_col = x[C.date].dt\n",
    "x[\"time\"] = date_col.hour + date_col.minute / 60\n",
    "\n",
    "x = x.drop(columns=[C.power, \"date\"])\n",
    "# x['date'] = x[C.date].dt.date\n",
    "# x = x.drop(columns=C.date)\n",
    "x = x.groupby([C.id]).median()  # agg(['mean', 'std'])\n",
    "# x.columns = ['mean', 'std']\n",
    "\n",
    "# alt.Chart(x).mark_point().encode(\n",
    "#     x='mean',\n",
    "#     y='std',\n",
    "# )\n",
    "\n",
    "x = x.reset_index().join(meta.set_index(C.id), on=C.id)\n",
    "\n",
    "_(x)\n",
    "\n",
    "alt.Chart(x).mark_point().encode(\n",
    "    x=\"time\",\n",
    "    y=\"orientation\",\n",
    ")\n",
    "\n",
    "# alt.Chart(x).mark_bar().encode(\n",
    "#     x = alt.X('time', bin=alt.Bin(maxbins=100)),\n",
    "#     y= 'count()',\n",
    "#     row='ss_id'\n",
    "# ).properties(height=75, width=200)\n",
    "\n",
    "# x = x[x[C.date].dt.year == 2020]\n",
    "# x = x[x[C.date].dt.month == 3]\n",
    "\n",
    "# _(x)#.reset_index())\n",
    "# return\n",
    "# alt.Chart(x).mark_line().encode(\n",
    "#     x=f'yearmonthdate({C.date})',\n",
    "#     y=alt.Y('time', scale=alt.Scale(domain=[10, 15], clamp=True)),\n",
    "#     row=alt.Row(C.id, spacing=1)\n",
    "# ).properties(height=70, width=800)\n",
    "# # _(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178c561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[[\"time\", \"orientation\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56701ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "_(couples.reset_index(drop=True), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fba88f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# trim to keep only a few days for given panels\n",
    "# data = x[x['power'] > 0.05 * x['power'].quantile(0.99)]\n",
    "# print('ok')\n",
    "\n",
    "# _(mer)\n",
    "\n",
    "idx = 12\n",
    "row = couples.iloc[idx]\n",
    "ss_id1 = row[\"ss_id1\"]\n",
    "ss_id2 = row[\"ss_id2\"]\n",
    "print(ss_id1)\n",
    "print(ss_id2)\n",
    "print(f'distance: {row[\"distance\"]}')\n",
    "\n",
    "\n",
    "data = mer.reset_index().copy()\n",
    "_(data)\n",
    "# data = data.reset_index()\n",
    "data = data[data[C.id].isin([ss_id1, ss_id2])].copy()\n",
    "\n",
    "# _(data)\n",
    "\n",
    "data = data.loc[data[C.date].dt.year == 2020]\n",
    "# data = data.loc[data[C.date].dt.month < 4]\n",
    "n = 100\n",
    "data = data.loc[data[C.date].dt.dayofyear.isin(list(range(n, n + 10)))]\n",
    "# data = data.sort_index().reset_index()#.copy()\n",
    "# display(meta.head())\n",
    "data = data.join(meta.set_index(C.id)[[C.lat, C.lon]], on=C.id)\n",
    "print(\"add\")\n",
    "\n",
    "print(\"data points for ss_id1\")\n",
    "_(data.groupby(C.id).count())\n",
    "\n",
    "_(data)\n",
    "\n",
    "# Add the elevation info\n",
    "if False:\n",
    "    from pvlib.solarposition import get_solarposition\n",
    "\n",
    "    def get_elevation(ts, lat, lon):\n",
    "        return get_solarposition(ts, lat, lon)[\"elevation\"].values[0]\n",
    "\n",
    "    print(get_elevation(datetime.datetime.now(), 34, -34))\n",
    "    print(len(data))\n",
    "    # data['azimuth'] = data[[C.date, C.lat, C.lon]].apply(lambda row: get_azimuth(*row), axis=1)\n",
    "    display(data.head())\n",
    "    data[\"elevation\"] = data[[C.date, C.lat, C.lon]].apply(\n",
    "        lambda row: get_elevation(row[C.date], row[C.lat], row[C.lon]), axis=1\n",
    "    )\n",
    "\n",
    "    # get_azimuth(datetime.datetime.now(), -45, 70)\n",
    "    # data.head()\n",
    "with_el = data\n",
    "_(with_el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765f073c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# _(with_el)\n",
    "# if False:\n",
    "#     with_el['elevation'] = with_el['min_cap']\n",
    "#     # Normalize elevation by the max for the max cap for the day\n",
    "#     max_cap = with_el[[C.id, C.date, 'cap', 'elevation']].copy()\n",
    "#     max_cap['date'] = max_cap[C.date].dt.date\n",
    "#     #y = y.set_index([C.id, C.date]).sort_index()\n",
    "#     max_cap = max_cap.groupby([C.id, 'date']).max()#.drop(columns=C.date)\n",
    "#     max_cap['max_cap/max_el'] = max_cap['cap'] / max_cap['elevation']\n",
    "#     #max_cap = max_cap.rename(columns={'cap': 'max_cap'}).drop(columns='timestamp')\n",
    "#     max_cap = max_cap.drop(columns=['cap', 'elevation', C.date])\n",
    "#     _(max_cap)\n",
    "\n",
    "#     y = data.copy()\n",
    "#     y['date'] = y[C.date].dt.date\n",
    "#     #y = y.set_index([C.id, 'date'])\n",
    "#     _(y)\n",
    "#     y = y.join(max_cap, on=[C.id, 'date'])\n",
    "#     y = y.drop(columns=['date'])\n",
    "#     _(y)\n",
    "# else:\n",
    "#     # Get the max of `cap` and `min_cap for each day\n",
    "#     t = with_el.copy()\n",
    "#     t = t[[C.id, C.date, 'cap', 'min_cap']]\n",
    "#     t['date'] = t[C.date].dt.date\n",
    "#     t = t.drop(columns=[C.date])\n",
    "#     t = t.groupby([C.id, 'date']).agg(['min', 'max'])\n",
    "#     _(t)\n",
    "#     # FIXME thisis skipped still we do nothing with `t`\n",
    "\n",
    "#     y = with_el.copy()\n",
    "y = with_el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a04b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = y.rename(columns={C.power: \"power\"})\n",
    "_(d)\n",
    "# d['power/cap'] = d['power'] / d['cap']\n",
    "\n",
    "# d['power/min_cap'] = d['power'] / (d['min_cap'])# * d['max_cap/max_el'])\n",
    "# d['power/min_cap norm'] = d['power/min_cap'] / d['max_cap/max_el']\n",
    "\n",
    "# d['special'] = (d['power'] - d['min_cap']) / (d['cap'] - d['min_cap'])\n",
    "\n",
    "# th = 0.2\n",
    "# below_th = (d['special'] < th).astype(float)\n",
    "\n",
    "# d['sqrt special'] = np.sqrt(d['special']) #(1 - below_th) * d['special'] + below_th * (d['power'] - d['min_cap']) / d['min_cap']\n",
    "# d['log special'] = np.log(d['special'])\n",
    "\n",
    "d[\"power/max\"] = d[\"power\"] / d[\"smooth_max\"]\n",
    "\n",
    "\n",
    "# d['special 2'] = (d['power'] - d['min_cap']) / (d['cap'] - d['min_cap']) ** 2\n",
    "# d['special_2'] = d['special']\n",
    "\n",
    "# d['power/min_cap'] = d['power'] / d['min_cap']\n",
    "\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3581241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacky merge of power/cap and power/elevation\n",
    "z = d.copy()\n",
    "threshold = 1\n",
    "# low_power_cap = (z['power/elevation'] < threshold).astype(float)\n",
    "# z['target'] = low_power_cap * z['power/elevation'] + (1 - low_power_cap) * z['power/cap']\n",
    "# z['target'] =\n",
    "\n",
    "_(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a2ec48",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = z.copy()\n",
    "\n",
    "stacked = (\n",
    "    data.set_index([C.id, C.date])\n",
    "    .drop(columns=[C.lat, C.lon])\n",
    "    .stack()\n",
    "    .to_frame()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"level_2\": \"metric\", 0: \"value\"})\n",
    "    .copy()\n",
    ")\n",
    "_(stacked, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92837c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd5ebaa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# distances = distances.sort_values('distance')\n",
    "# d = distances[distances['ss_id1'].isin(ids) & distances['ss_id2'].isin(ids)\n",
    "\n",
    "\n",
    "# data = data[data['']]\n",
    "\n",
    "chart = (\n",
    "    (\n",
    "        alt.Chart(stacked)\n",
    "        .mark_line()\n",
    "        .encode(\n",
    "            x=f\"hoursminutes({C.date})\",\n",
    "            # y=C.power,\n",
    "            y=\"value\",\n",
    "            row=alt.Row(f\"yearmonthdate({C.date})\", spacing=1),\n",
    "            column=alt.Column(\n",
    "                \"metric\", spacing=1\n",
    "            ),  # , sort=['power', 'cap', 'elevation', 'power/cap']),\n",
    "            # facet=alt.Facet(f'yearmonthdate({C.date})', columns=6, spacing=1),\n",
    "            color=C.id + \":N\",\n",
    "        )\n",
    "    )\n",
    "    .properties(width=200, height=75)\n",
    "    .resolve_scale(\n",
    "        # x='independent',\n",
    "        y=\"independent\"\n",
    "    )\n",
    ")\n",
    "display(chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f501b35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = neighbor_data.copy()\n",
    "display(data.head())\n",
    "\n",
    "\n",
    "def plot(ss_id1, ss_id2, dist):\n",
    "\n",
    "    d = data.loc[\n",
    "        data[C.id].isin([int(ss_id1), int(ss_id2)]), [C.id, C.power, C.date]\n",
    "    ].copy()\n",
    "    display(d)\n",
    "    #     if len(d) < 100:\n",
    "    #         print('uh oh')\n",
    "    #         return\n",
    "    d[C.id] = d[C.id].astype(str)\n",
    "    d = pd.pivot(d, index=C.date, columns=C.id, values=C.power).reset_index()\n",
    "    display(d.head())\n",
    "    #     print(d.corr()[ss_id1][ss_id2])\n",
    "    #     print(d.isnull().max(axis=1).mean())\n",
    "    #     print(len(d))\n",
    "\n",
    "    #     display(d.head())\n",
    "    #     if d.isnull().max(axis=1).sum() / len(d) > 0.5:\n",
    "    #         print('uh oh')\n",
    "    #         return\n",
    "\n",
    "    def round_to(x, t):\n",
    "        return round(x / t) * t\n",
    "\n",
    "    x = d[C.date].dt.hour\n",
    "    d[\"hours\"] = round_to(x, 3)\n",
    "    m = x * 60 + d[C.date].dt.minute\n",
    "    d[\"minute\"] = m - d[\"hours\"] * 60 + 60\n",
    "    d[\"month\"] = round_to(d[C.date].dt.month, 3)\n",
    "    #     d['minute'] = d[C.date].dt.minute\n",
    "\n",
    "    chart = (\n",
    "        alt.Chart(d.sample(10000))\n",
    "        .mark_circle(size=12, opacity=0.6)\n",
    "        .encode(\n",
    "            x=alt.X(str(int(ss_id1)), title=\"\"),\n",
    "            y=alt.Y(str(int(ss_id2)), title=\"\"),\n",
    "            #             color=alt.Color(f'month({C.date}):N', scale=alt.Scale(scheme='viridis')),\n",
    "            #             color=alt.Color(f'minute', scale=alt.Scale(scheme='viridis')),\n",
    "            color=alt.Color(f\"hours({C.date}):O\", scale=alt.Scale(scheme=\"viridis\")),\n",
    "            #             row=alt.Row(f'hoursminutes({C.date})', bin=True),\n",
    "            # row=alt.Row(f'hours', spacing=1),\n",
    "            # column=alt.Column(f'month', spacing=1),\n",
    "            facet=alt.Facet(f\"month({C.date})\", columns=4, spacing=1),\n",
    "        )\n",
    "        #      ).properties(width=800, height=800, title=f'Distance = {dist * 1000:.0f}m')\n",
    "    ).properties(\n",
    "        width=150,\n",
    "        height=150,\n",
    "        title=f\"Power of pv={ss_id1} vs pv={ss_id2} (distance={dist * 1000:.0f}m)\",\n",
    "    )\n",
    "    return chart\n",
    "\n",
    "\n",
    "plot(ss_id1, ss_id2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d84c64d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ab55d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a57267",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Power distribution (over a couple of days) for a given time of day, for a give PV system.\n",
    "\n",
    "t = power.copy()\n",
    "t = t.loc[[ss_id1, ss_id2]]\n",
    "t[C.date] = t.index.get_level_values(1)\n",
    "t[C.id] = t.index.get_level_values(0)\n",
    "\n",
    "# keep only some days\n",
    "t = t[t[C.date].dt.year == 2020]\n",
    "\n",
    "n = 200\n",
    "t = t.loc[t[C.date].dt.dayofyear.isin(list(range(n - 10, n + 20)))]\n",
    "# t = t[t[C.date].dt.month == 10]\n",
    "\n",
    "t = t.reset_index(drop=True)\n",
    "_(t)\n",
    "chart = (\n",
    "    (\n",
    "        alt.Chart(t)\n",
    "        .mark_bar(opacity=0.3, binSpacing=0)\n",
    "        .encode(\n",
    "            x=alt.X(C.power, bin=alt.Bin(maxbins=50)),\n",
    "            y=alt.Y(\"count()\", stack=None, title=\"\"),\n",
    "            row=alt.Row(f\"hours({C.date})\", spacing=1),\n",
    "            # column=alt.Column(f'month({C.date})', spacing=1),\n",
    "            color=C.id + \":N\",\n",
    "        )\n",
    "    )\n",
    "    .properties(width=150, height=50)\n",
    "    .resolve_scale(\n",
    "        #   x=\"independent\",\n",
    "        y=\"independent\",\n",
    "    )\n",
    ")\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac3106c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Power distribution (over a couple of days) for a given time of day, for a give PV system.\n",
    "# import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "t = power.copy()\n",
    "t = t.loc[[ss_id1, ss_id2]]\n",
    "t[C.date] = t.index.get_level_values(1)\n",
    "t[C.id] = t.index.get_level_values(0)\n",
    "t[\"time_of_day\"] = t[C.date].dt.hour * 60 + t[C.date].dt.minute\n",
    "\n",
    "# keep only some days\n",
    "t = t[t[C.date].dt.year == 2020]\n",
    "\n",
    "# n = 200 - 14\n",
    "t = t.loc[\n",
    "    t[C.date].dt.dayofyear.isin(\n",
    "        list(\n",
    "            range(\n",
    "                200 - 14,\n",
    "                200 + 10 + 14,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "]\n",
    "# t = t[t[C.date].dt.month == 10]\n",
    "\n",
    "t = t.reset_index(drop=True)\n",
    "_(t)\n",
    "\n",
    "for idx, row in tqdm(t.iterrows(), total=len(t)):\n",
    "    #     print(idx)\n",
    "    ss_id = row[C.id]\n",
    "    p = row[C.power]\n",
    "    ts = row[C.date]\n",
    "    doy = ts.day_of_year\n",
    "\n",
    "    time_of_day = ts.hour * 60 + ts.minute\n",
    "    #    hour = ts.hour\n",
    "    #  print(idx)\n",
    "    #    break\n",
    "\n",
    "    #     print(ts)\n",
    "    #     print(doy)\n",
    "    #     print(hour)\n",
    "\n",
    "    day_radius = 7\n",
    "    time_radius = 15\n",
    "\n",
    "    # Gather other values for this hours in the days around\n",
    "\n",
    "    #     similar_old = t[\n",
    "    #         (t[C.id] == ss_id)\n",
    "    #         & (t['time_of_day'] == time_of_day)\n",
    "    #         & (abs(t[C.date].dt.day_of_year - doy) <= 7)].copy()\n",
    "\n",
    "    #     similar_new_narrow = t[\n",
    "    #         (t[C.id] == ss_id)\n",
    "    #         & (abs(t['time_of_day'] - time_of_day) < 15)\n",
    "    #         & (abs(t[C.date].dt.day_of_year - doy) <= 7)].copy()\n",
    "\n",
    "    similar_new_wide = t[\n",
    "        (t[C.id] == ss_id)\n",
    "        & (abs(t[\"time_of_day\"] - time_of_day) < 30)\n",
    "        & (abs(t[C.date].dt.day_of_year - doy) <= 14)\n",
    "    ].copy()\n",
    "\n",
    "    # TODO\n",
    "    #    similar_new = t[]\n",
    "    # TODO Do some interpolate instead of just doing the mean.\n",
    "    # See: https://stackoverflow.com/a/26490248/1067132\n",
    "    #     for name, similar in zip(['old', 'narrow', 'wide'], [similar_old, similar_new_narrow, similar_new_wide]):\n",
    "    for name, similar in [[\"\", similar_new_wide]]:\n",
    "        z = (similar[C.power] < p).mean()\n",
    "        t.loc[idx, \"z_\" + name] = z\n",
    "\n",
    "    max_ = (similar[C.power]).max()\n",
    "    t.loc[idx, \"old\"]\n",
    "    # max_ = similar[C.power].max()\n",
    "    # min_ = similar[C.power].min()\n",
    "    # t.loc[idx, 'p/max_' + name] = p / max_\n",
    "    # spread = max_ - min_\n",
    "    # t.loc[idx, '(p-min)/(max-min)_' + name] = 0 if spread == 0 else (p - min_) / (max_ - min_)\n",
    "\n",
    "#     z_old = (similar_old[C.power] < p).mean()\n",
    "#     t.loc[idx, 'z'] = z\n",
    "#     t.loc[idx, 'max'] = similar[C.power].max()\n",
    "#     t.loc[idx, 'min'] = similar[C.power].min()\n",
    "_(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8c12a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tt = t.copy()\n",
    "tt = tt.set_index([C.id, C.date])\n",
    "# tt['power / max'] = tt[C.power] / tt['max']\n",
    "tt = tt.drop(columns=[\"time_of_day\"])  # , 'min', 'max'])\n",
    "tt = (\n",
    "    tt.stack()\n",
    "    .to_frame()\n",
    "    .reset_index(2)\n",
    "    .rename(columns={\"level_2\": \"metric\", 0: \"value\"})\n",
    ")\n",
    "tt = tt.reset_index()\n",
    "\n",
    "\n",
    "_(tt)\n",
    "\n",
    "# print(tt['metric'] == C.power)\n",
    "# print(C.power)\n",
    "tt = tt.loc[\n",
    "    tt[C.date].dt.dayofyear.isin(\n",
    "        list(\n",
    "            range(\n",
    "                200,\n",
    "                200 + 10,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "]\n",
    "# tt = tt[tt['metric'] == C.power]\n",
    "\n",
    "tt = tt[tt[\"metric\"] == \"z_\"]\n",
    "\n",
    "alt.Chart(tt).mark_line().encode(\n",
    "    y=\"value\",\n",
    "    x=f\"hoursminutes({C.date})\",\n",
    "    row=alt.Column(f\"yearmonthdate({C.date})\", spacing=1),\n",
    "    column=alt.Column(\"metric\", spacing=1),\n",
    "    color=C.id + \":N\",\n",
    ").resolve_scale(\n",
    "    #      x=\"independent\",\n",
    "    #  y=\"independent\",\n",
    ").properties(\n",
    "    width=400, height=150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fbd609",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# display(d.head())\n",
    "# i = 0\n",
    "# for _, (ss_id1, ss_id2, dist) in d.sort_values('distance').iterrows():\n",
    "# #     print(dist)\n",
    "# #     if dist == 0:\n",
    "# #         continue\n",
    "#     display(plot(str(int(ss_id1)), str(int(ss_id2)), dist))\n",
    "#     i += 1\n",
    "\n",
    "#     if i > 30:\n",
    "#         break\n",
    "\n",
    "# return\n",
    "\n",
    "\n",
    "c = data[[C.id, C.power, C.date]].copy()\n",
    "c[C.id] = c[C.id].astype(str)\n",
    "c = pd.pivot(c, index=C.date, columns=C.id, values=C.power)\n",
    "\n",
    "display(c.head())\n",
    "\n",
    "cc = c.iloc[:, :10].copy()\n",
    "display(cc.head())\n",
    "ids = list(cc.columns)\n",
    "# cc[C.id] = cc[C.id].astype(str)\n",
    "# ids = list(map(str, list(cc.columns)))\n",
    "print(ids)\n",
    "# return\n",
    "alt.Chart(cc).mark_circle(opacity=0.6, size=5).encode(\n",
    "    alt.X(alt.repeat(\"column\"), type=\"quantitative\"),\n",
    "    alt.Y(alt.repeat(\"row\"), type=\"quantitative\"),\n",
    "    color=alt.Color(f\"month({C.date}):N\", scale=alt.Scale(scheme=\"viridis\")),\n",
    ").properties(width=20, height=20).repeat(row=ids, column=ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6061fbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(meta.set_index(\"ss_id\").loc[26934])\n",
    "display(meta.set_index(\"ss_id\").loc[4035])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9349c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = c.corr().stack()\n",
    "display(c.head())\n",
    "# c = c.stack()\n",
    "# dd = d.set_index(('ss_id1', 'ss_id2'))\n",
    "display(d.head())\n",
    "display(dd.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
